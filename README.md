# üè† Assistente T√©cnico Minha Casa Minha Vida

> **Este projeto foi desenvolvido como parte do bootcamp da DIO: Microsoft Certification Challenge #4 - DP 100.**

Este projeto desenvolve um assistente inteligente da **Caixa Econ√¥mica Federal** capaz de responder d√∫vidas sobre financiamento habitacional, uso do FGTS, contratos, etapas do programa e regras operacionais do Minha Casa Minha Vida. O sistema utiliza **Recupera√ß√£o Aumentada por Gera√ß√£o (RAG)** para garantir respostas fundamentadas em documentos oficiais.

---

## üìå Objetivo

Oferecer uma solu√ß√£o institucional que torne o acesso √† informa√ß√£o mais √°gil e confi√°vel, especialmente em contextos operacionais e sociais. A t√©cnica de RAG garante que as respostas estejam sempre baseadas em documentos oficiais da Caixa.

---

## üß© Estrutura do Projeto

    ‚îú‚îÄ‚îÄ app/                 # Pasta principal do projeto
    ‚îÇ   ‚îú‚îÄ‚îÄ app.py           # Interface Streamlit
    ‚îÇ   ‚îú‚îÄ‚îÄ rag_core.py      # N√∫cleo RAG: embeddings, FAISS, LLM e cadeia de resposta
    ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Configura√ß√µes centrais
    ‚îÇ   ‚îú‚îÄ‚îÄ index_mcmv/      # √çndice FAISS j√° constru√≠do
    ‚îÇ   ‚îú‚îÄ‚îÄ documentos/      # Base de conhecimento (PDFs e DOCXs)
    ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt # Lista de depend√™ncias

---

## ‚öôÔ∏è Tecnologias Utilizadas

| Ferramenta/Biblioteca     | Finalidade                                     |
| ------------------------- | ---------------------------------------------- |
| **LangChain**             | Pipeline RAG e integra√ß√£o com o modelo         |
| **FAISS**                 | Indexa√ß√£o vetorial e busca sem√¢ntica           |
| **Sentence Transformers** | Gera√ß√£o de embeddings sem√¢nticos               |
| **Ollama**                | Execu√ß√£o local do modelo de linguagem          |
| **Streamlit**             | Interface web interativa para o usu√°rio        |
| **Python**                | Linguagem base para desenvolvimento do sistema |

---

## üöÄ Instala√ß√£o e Execu√ß√£o

### 1. Clone o reposit√≥rio

    git clone https://github.com/matheusfgb2/chatbot_rag_dio.git
    cd chatbot_rag_dio/app

---

### 2. Instale o Ollama

**Windows**: [https://ollama.com/download](https://ollama.com/download)  
**Linux/macOS**:

    curl -fsSL https://ollama.com/install.sh | sh

Depois:

    ollama pull llama3.1
    ollama serve

> O Ollama deve estar rodando em segundo plano para que o assistente funcione.

---

### 3. Crie e ative o ambiente virtual

**Windows**:

    python -m venv .venv
    .venv\Scripts\activate

**Linux/macOS**:

    python3 -m venv .venv
    source .venv/bin/activate

---

### 4. Instale as depend√™ncias

    pip install -r requirements.txt

> O processo pode levar alguns minutos. O tamanho total dos pacotes pode ultrapassar 2GB.

---

### 5. Execute o assistente

    streamlit run app.py

A interface estar√° dispon√≠vel em:

    http://localhost:8501

> Na primeira execu√ß√£o, o carregamento pode demorar alguns segundos.  
> Se aparecer o erro `WinError 10061`, certifique-se de que o Ollama est√° rodando com `ollama serve`.

---

### 6. Desativar o ambiente virtual

    deactivate

---

## üìÅ Documenta√ß√£o T√©cnica da Indexa√ß√£o

- Os documentos foram segmentados e vetorizados com `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`.
- O √≠ndice FAISS foi gerado e salvo na pasta `index_mcmv/`.
- O sistema utiliza busca sem√¢ntica com `search_type="mmr"` para equilibrar relev√¢ncia e diversidade.

> O √≠ndice j√° est√° pronto e inclu√≠do no reposit√≥rio. N√£o √© necess√°rio reindexar os documentos.

---

## ‚è±Ô∏è Considera√ß√µes Finais

- O tempo m√©dio de resposta √© de aproximadamente 1 minuto, dependendo da pergunta e dos recursos da m√°quina.
- A execu√ß√£o fora do Docker elimina overhead e melhora o desempenho local.
- Mantenha o modelo previamente baixado e o ambiente virtual ativo para garantir inicializa√ß√£o r√°pida e respostas consistentes.
